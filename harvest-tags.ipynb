{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvest public tags from Trove zones\n",
    "\n",
    "This notebook harvests all the public tags that users have added to records in Trove. However, tags are being added all the time, so by the time you've finished harvesting, the dataset will probably be out of date.\n",
    "\n",
    "You can access tags via the API by adding `has:tags` to the query parameter to limit results to records with tags, and then adding the `include=tags` parameter to include the tag data in each item record.\n",
    "\n",
    "The `harvest_tags()` function harvests all tags from the specified zone and writes them to a CSV file named according to the zone, for example, `tags_newspaper.csv`.\n",
    "\n",
    "Each CSV file contains the following columns:\n",
    "\n",
    "* `tag` – the text tag\n",
    "* `date` – date the tag was added\n",
    "* `zone` – the Trove API zone (eg 'newspaper', 'book')\n",
    "* `record_id` – the id of the record to which the tag has been added\n",
    "\n",
    "Once the zone harvests are complete you can use this notebook to combine the separate CSV files, normalise the capitalisation of tags, and save the complete results into a single CSV file.\n",
    "\n",
    "Some things to note:\n",
    "\n",
    "* Works (like books) can have tags attached at either `work` or `version` level. To simplify things, this code aggregates all tags at the work level, removing any duplicates.\n",
    "* A single resource in Trove can appear in multiple zones – for example, a book that includes maps and illustrations might appear in the 'book', 'picture', and 'map' zones. This means that some of the tags will essentially be duplicates – harvested from different zones, but relating to the same resource.\n",
    "* User content added to Trove, including tags, is available for reuse under a CC-BY-NC licence.\n",
    "\n",
    "The complete dataset created by this notebook in July 2021 is available for download from [CloudStor](https://cloudstor.aarnet.edu.au/plus/s/YiWStNrhnTo18JI) and [Zenodo](https://doi.org/10.5281/zenodo.5094314).\n",
    "\n",
    "For some examples of how you might analyse and visualise the harvested tags, see [this notebook](analyse_tags.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import requests_cache\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "s = requests_cache.CachedSession()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[ 500, 502, 503, 504 ])\n",
    "s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "s.mount('https://', HTTPAdapter(max_retries=retries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = 'http://api.trove.nla.gov.au/v2/result'\n",
    "\n",
    "# Set basic parameters\n",
    "params = {\n",
    "    'q': 'has:tags',\n",
    "    'include': 'tags',\n",
    "    'encoding': 'json',\n",
    "    'bulkHarvest': 'true',\n",
    "    'n': 100,\n",
    "    'key': 'YOUR API KEY'\n",
    "}\n",
    "\n",
    "# These types are needed to get data from API results\n",
    "record_types = {\n",
    "    'newspaper': 'article', \n",
    "    'gazette': 'article', \n",
    "    'book': 'work', \n",
    "    'article': 'work', \n",
    "    'picture': 'work', \n",
    "    'music': 'work', \n",
    "    'map': 'work', \n",
    "    'collection': 'work', \n",
    "    'list': 'list'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total(cparams):\n",
    "    '''\n",
    "    This will enable us to make a nice progress bar...\n",
    "    '''\n",
    "    response = s.get(api_url, params=cparams)\n",
    "    data = response.json()\n",
    "    return int(data['response']['zone'][0]['records']['total'])\n",
    "\n",
    "def get_tags_from_record(record):\n",
    "    '''\n",
    "    Extract tags from the supplied record.\n",
    "    Returns a list of tags.\n",
    "    Each tag is a list with two elements – value and date.\n",
    "    '''\n",
    "    tags = []\n",
    "    try:\n",
    "        for tag in record['tag']:\n",
    "            tag_data = [tag.get('value'), tag.get('lastupdated')]\n",
    "            tags.append(tag_data)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return tags\n",
    "\n",
    "def harvest_tags(zone):\n",
    "    '''\n",
    "    Harvest public tags from the specified zone.\n",
    "    Results are written to a CSV file.\n",
    "    '''\n",
    "    print(zone)\n",
    "    # article, work, or list\n",
    "    record_type = record_types[zone]\n",
    "    # Delete existing data file\n",
    "    Path(f'tags_{zone}.csv').unlink(missing_ok=True)\n",
    "    # Write column headings\n",
    "    with Path(f'tags_{zone}.csv').open('a') as tag_file:\n",
    "        writer = csv.writer(tag_file)\n",
    "        writer.writerow(['tag', 'date', 'zone', 'record_id'])\n",
    "    start = '*'\n",
    "    cparams = params.copy()\n",
    "    cparams['zone'] = zone\n",
    "    # If it's a work, get versions as well\n",
    "    if record_type == 'work':\n",
    "        cparams['include'] = 'tags,workversions'\n",
    "    total = get_total(cparams)\n",
    "    with tqdm(total=total) as pbar:\n",
    "        while start is not None:\n",
    "            cparams['s'] = start\n",
    "            response = s.get(api_url, params=cparams)\n",
    "            data = response.json()\n",
    "            results = data['response']['zone'][0]['records']\n",
    "            # Get token for next page\n",
    "            try:\n",
    "                start = results['nextStart']\n",
    "            # End of the result set\n",
    "            except KeyError:\n",
    "                start = None\n",
    "            with Path(f'tags_{zone}.csv').open('a') as tag_file:\n",
    "                writer = csv.writer(tag_file)\n",
    "                for record in results[record_type]:\n",
    "                    tags = []\n",
    "                    tags += get_tags_from_record(record)\n",
    "                    # If there are versions loop through them gathering tags\n",
    "                    if 'version' in record:\n",
    "                        for version in record['version']:\n",
    "                            tags += get_tags_from_record(version)\n",
    "                    # Remove duplicate tags on work\n",
    "                    tags = [list(t) for t in {tuple(l) for l in tags }]\n",
    "                    # \n",
    "                    if len(tags) == 0:\n",
    "                        print(record)\n",
    "                    # Add zone and record_id, then write to CSV\n",
    "                    for tag in tags:\n",
    "                        tag.append(zone)\n",
    "                        tag.append(record['id'])\n",
    "                        writer.writerow(tag)\n",
    "            pbar.update(len(results[record_type]))\n",
    "            if not response.from_cache:\n",
    "                time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zone in ['newspaper', 'gazette', 'book', 'article', 'picture', 'music', 'map', 'collection', 'list']:\n",
    "    harvest_tags(zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the tag files and convert to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "      <th>zone</th>\n",
       "      <th>record_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Guihen</td>\n",
       "      <td>2013-03-24T02:30:11Z</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>100000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HICKEN Aberaham - Barellan</td>\n",
       "      <td>2019-12-03T23:02:10Z</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>100000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WAIDE</td>\n",
       "      <td>2014-04-02T06:39:06Z</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>100000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pannowitz-Rhode wedding 1912</td>\n",
       "      <td>2013-02-28T00:47:10Z</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>100000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAIDE</td>\n",
       "      <td>2014-04-02T06:39:32Z</td>\n",
       "      <td>newspaper</td>\n",
       "      <td>100000106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            tag                  date       zone  record_id\n",
       "0                Stephen Guihen  2013-03-24T02:30:11Z  newspaper  100000011\n",
       "1    HICKEN Aberaham - Barellan  2019-12-03T23:02:10Z  newspaper  100000071\n",
       "2                         WAIDE  2014-04-02T06:39:06Z  newspaper  100000098\n",
       "3  Pannowitz-Rhode wedding 1912  2013-02-28T00:47:10Z  newspaper  100000101\n",
       "4                         WAIDE  2014-04-02T06:39:32Z  newspaper  100000106"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for zone in ['newspaper', 'gazette', 'book', 'article', 'picture', 'music', 'map', 'collection', 'list']:\n",
    "    dfs.append(pd.read_csv(f'tags_{zone}.csv'))\n",
    "df = pd.concat(dfs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many tags are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8722292, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise capitalisation and save as CSV\n",
    "\n",
    "Cases are mixed in tags, although tag search in Trove is case-insensitive. Here we'll convert all the tags to lower-case, so we can aggregate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag_normalised'] = df['tag'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things compact, we'll drop the mixed-case tags and rename the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unnormalised tag column\n",
    "df.drop(columns='tag', inplace=True)\n",
    "# Rename the lowercase tag column\n",
    "df.rename(columns={'tag_normalised': 'tag'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save the complete, normalised dataset to a single CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns and save as CSV\n",
    "df[['tag', 'date', 'zone', 'record_id']].to_csv('trove_tags_20210710.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Created by [Tim Sherratt](https://timsherratt.org/) for the [GLAM Workbench](https://glam-workbench.net/). Support this project by becoming a [GitHub sponsor](https://github.com/sponsors/wragge)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
