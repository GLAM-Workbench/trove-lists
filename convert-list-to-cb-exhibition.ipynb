{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert a Trove list into a CollectionBuilder exhibition\n",
    "\n",
    "This notebook converts [Trove lists](https://trove.nla.gov.au/help/become-voluntrove/lists) into a series of files that can be uploaded to a [CollectionBuilder-GH](https://github.com/CollectionBuilder/collectionbuilder-gh) repository to create an instant exhibition. See the [CollectionBuilder site](https://collectionbuilder.github.io/) for more information on how CollectionBuilder works and what it can do.\n",
    "\n",
    "**Demo**: [this exhibition](https://wragge.github.io/trove-wragge-list-demo/) was generated from this [Trove list](https://trove.nla.gov.au/list/83777).\n",
    "\n",
    "#### 1. What you need\n",
    "\n",
    "* a [Trove API key](https://trove.nla.gov.au/about/create-something/using-api#getting-an-api-key) (copy & paste your key where indicated below)\n",
    "* a [GitHub account](https://github.com/signup)\n",
    "* a [Trove List](https://trove.nla.gov.au/help/become-voluntrove/lists) containing items you want to include in your exhibition\n",
    "\n",
    "#### 2. Setup a GitHub repository for your exhibition\n",
    "\n",
    "1. Login to your GitHub account.\n",
    "2. Go to my [customised CollectionBuilder-GH template repository](https://github.com/wragge/collectionbuilder-gh-trove).\n",
    "3. Click on the big green **Use this template** button.\n",
    "4. Give your repository a name by typing in the **Repository name** box – the name of the repository will form part of the url for your new exhibition, so you probably want to give it a name that relates to the exhibition.\n",
    "5. Click on the big green **Create a repository from template** button. You'll be automatically redirected to your new repository.\n",
    "\n",
    "#### 3. Enable GitHub Pages for your repository\n",
    "\n",
    "GitHub builds your exhibition from the files in the repository using GitHub Pages. You need to enable this after you create your repository:\n",
    "\n",
    "1. Click on the **Settings** button in your new repository.\n",
    "2. Click on the **Pages** button in the side menubar.\n",
    "3. Under **Branch** select 'main' from the dropdown list and click on **Save**.\n",
    "\n",
    "GitHub will now build your exhibition. Once it's ready you'll see a link on the 'Pages' page. The url will have the form `https://[your GH user name].github.io/[your repository name]`. At the moment the exhibition will contain dummy data – the next step is to generate your own exhibition data! \n",
    "\n",
    "#### 4. Generate your exhibition files from your Trove list\n",
    "\n",
    "1. Find your Trove list's numeric id. The list id is the number in the url of your Trove list. So [the list](https://trove.nla.gov.au/list/83774) with this url `https://trove.nla.gov.au/list/83774` has an id of `83774`.\n",
    "2. Copy and paste your *list id* and *Trove API key* where indicated below in this notebook,\n",
    "3. From the Jupyter **Run** menu select **Run all cells**.\n",
    "4. When everything has finished running, a link to a zip file will be displayed at the bottom of the notebook. Download it to your own computer and open the zip file. Done!\n",
    "\n",
    "#### 5. Add more metadata (optional)\n",
    "\n",
    "The metadata describing the items in your exhibition is contained in the `_data/[list id]-items.csv` file. If the items in your exhibition relate to specific places, you may want to add some extra metadata so that CollectionBuilder can display them on a map.\n",
    "\n",
    "Information about places is contained in three columns: `location`, `latitude`, and `longitude`. In the `location` field you can include a list of place names, separated by semicolons, eg: 'Melbourne; Sydney; Hobart'. These placenames will be used to build a word cloud when you click on the **Location** tab in your exhibition. \n",
    "\n",
    "To add an item to CollectionBuilder's map view, you need to supply values for `latitude` and `longitude`.\n",
    "\n",
    "You might also want to edit the `subject`, and `description` fields.\n",
    "\n",
    "1. Open your metadata file with either a text editor or a spreadsheet program (but beware that some programs, like Excel, might mangle your dates).\n",
    "2. Edit the desired values.\n",
    "3. Make sure the edited file is saved in CSV (plain text) format, replacing the original metadata file.\n",
    "\n",
    "Note that GitHub has it's own built-in file editor. So if you don't have a way of editing the CSV file on your own computer, just skip down to the 'Upload your files...' section below and add them to your GitHub repository. To edit the file just view it in GitHub and click on the pencil icon. Once you've finished editing, make sure you click the **Commit** button to save your changes.\n",
    "\n",
    "#### 6. Replace tiny images (optional)\n",
    "\n",
    "Trove work records often only include links to tiny thumbnailed versions of images. These don't look great in an exhibition, so you might want to replace them. Different collections use different image viewers, so there's no easy, automated way to do this. You'll have to manually download them and replace the thumnailed versions.\n",
    "\n",
    "1. From the Trove work record, click on the **View** button and open the link to the original item.\n",
    "2. Use whatever download mechanism is provided to save a copy of the image on your computer.\n",
    "3. Rename the downloaded image to match the name of the tiny thumbnailed version in your exhibition's `objects` directory.\n",
    "4. Replace the thumbnail image in the `objects` directory with the new downloaded version.\n",
    "\n",
    "#### 7. Upload your files to the exhibition repository\n",
    "\n",
    "You're now ready to add your exhibition files to the exhibition repository!\n",
    "\n",
    "1. Go to the GitHub repository you created above.\n",
    "2. Click on the **Add file** button and select **Upload files**.\n",
    "3. Select the `_config.yml` file in the exhibition files you downloaded from this notebook.\n",
    "4. Click on the green **Commit changes** button to save the file in your repository.\n",
    "5. Open the `_data` directory in your GitHub repository.\n",
    "6. Click on the **Add file** button and select **Upload files**.\n",
    "7. Select the `_data/[list id]-items.csv` file in your exhibition files.\n",
    "8. Click on the green **Commit changes** button to save the file in your repository.\n",
    "9. Open the `objects` directory in your GitHub repository.\n",
    "10. Select all the files in the `objects` directory of your exhibition files.\n",
    "11. Click on the green **Commit changes** button to save the files in your repository.\n",
    "\n",
    "Once you've uploaded the files, GitHub will rebuild the exhibition using your data. It might take a little while to generate, but once it's ready you see it at `https://[your GH user name].github.io/[your repository name]`.\n",
    "\n",
    "If your not happy with the metadata and how it displays, you can either edit the exhibition files on your own computer and re-upload them to GitHub. Or you can use GitHub's built-in file editor to make changes. To edit a file just view it in GitHub and click on the pencil icon. Once you've finished editing, make sure you click the **Commit** button to save your changes.\n",
    "\n",
    "Every time you make a change to your repository, GitHub will automatically rebuild your exhibition.\n",
    "\n",
    "#### 8. Further customisation\n",
    "\n",
    "You can further customise the look and feel of your exhibition by editing the `_data/theme.yml` file. For example, you can:\n",
    "\n",
    "* Set a different `featured-image` to display in the header of your exhibition.\n",
    "* Change the `latitude` and `longitude` values to set the centre on the map view.\n",
    "\n",
    "See the [CollectionBuilder documentation](https://collectionbuilder.github.io/cb-docs/docs/theme/) for more options.\n",
    "\n",
    "\n",
    "#### Annotating Trove list items\n",
    "\n",
    "You can add your own annotations to Trove list items and these will automatically be included in your exhibition. To add a descriptive note:\n",
    "\n",
    "1. Make sure you're logged in to your Trove account.\n",
    "2. Go to your list (you can find a list of your lists in your Trove user profile).\n",
    "3. Go to the item in your list you want to annotate and click on the **Add list item note button**.\n",
    "4. Add your note.\n",
    "\n",
    "Your note will be added to the `description` field of the item when you generate your exhibition files. In addition, any tags added to items in your list will be added to the `subject` field.\n",
    "\n",
    "Note that if you make changes to your list, you'll need to regenerate the exhibition files using this notebook and upload them to your GitHub repository before the changes are visible in your exhibition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from io import BytesIO\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import HTML\n",
    "from lat_lon_parser import parse\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from PIL.ImageOps import contain\n",
    "from pymarc import JSONReader\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from tqdm.auto import tqdm\n",
    "from trove_newspaper_images.articles import download_images\n",
    "\n",
    "s = requests.Session()\n",
    "retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])\n",
    "s.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add your API key and list ID values\n",
    "\n",
    "This is the only section that you'll need to edit. Paste your API key and list id in the cells below as indicated. Once you've finished, select **Run all cells** from the **Run** menu to generate your exhibition files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your Trove API key between the quotes\n",
    "API_KEY = \"YOUR API KEY\"\n",
    "\n",
    "# Use api key value from environment variables if it is available\n",
    "if os.getenv(\"TROVE_API_KEY\"):\n",
    "    API_KEY = os.getenv(\"TROVE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your list id between the quotes\n",
    "list_id = \"83777\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Geo areas data\n",
    "response = s.get(\n",
    "    \"https://raw.githubusercontent.com/GLAM-Workbench/marc-geographicareas/main/marc_geographicareas.json\"\n",
    ")\n",
    "GEO_AREAS = response.json()\n",
    "\n",
    "\n",
    "def get_metadata(id):\n",
    "    \"\"\"\n",
    "    Extract work data in a JSON string from the work's HTML page.\n",
    "    \"\"\"\n",
    "    if not id.startswith(\"http\"):\n",
    "        id = \"https://nla.gov.au/\" + id\n",
    "    response = requests.get(id)\n",
    "    try:\n",
    "        work_data = re.search(\n",
    "            r\"var work = JSON\\.parse\\(JSON\\.stringify\\((\\{.*\\})\", response.text\n",
    "        ).group(1)\n",
    "    except AttributeError:\n",
    "        work_data = \"{}\"\n",
    "    return json.loads(work_data)\n",
    "\n",
    "\n",
    "def parse_marc(metadata):\n",
    "    \"\"\"\n",
    "    Parse the bibliographic MARC data in the embedded metadata.\n",
    "    This produces a structure that can be loaded into PyMarc's JSON reader.\n",
    "    \"\"\"\n",
    "    # Some nla.obj items don't have MARC data\n",
    "    # For example some collections\n",
    "    try:\n",
    "        records = metadata[\"marcData\"][\"record\"]\n",
    "    except KeyError:\n",
    "        return {}\n",
    "\n",
    "    # The metadata contains bibliographic and holdings MARC data\n",
    "    # here we'll select the bib record.\n",
    "    for record in records:\n",
    "        if record[\"leader\"].get(\"type\") == \"Bibliographic\":\n",
    "            break\n",
    "\n",
    "    fields = []\n",
    "    # Control fields only have content, no subfields\n",
    "    for cf in record.get(\"controlfield\", []):\n",
    "        fields.append({str(cf[\"tag\"]): str(cf[\"content\"])})\n",
    "\n",
    "    # Loop through all the fields\n",
    "    for field in record[\"datafield\"]:\n",
    "        subfields = []\n",
    "        # Get any subfields\n",
    "        sfs = field.get(\"subfield\", [])\n",
    "        # The subfields value can be a list or dict\n",
    "        # Check if it's a list\n",
    "        if isinstance(sfs, list):\n",
    "            # Loop through the subfields adding the values\n",
    "            for sf in sfs:\n",
    "                subfields.append({sf[\"code\"]: str(sf[\"content\"])})\n",
    "        # If it's not a list just add the details from the dict\n",
    "        else:\n",
    "            subfields.append({sfs[\"code\"]: str(sfs[\"content\"])})\n",
    "        fields.append(\n",
    "            {\n",
    "                str(field[\"tag\"]): {\n",
    "                    \"subfields\": subfields,\n",
    "                    \"ind1\": field[\"ind1\"],\n",
    "                    \"ind2\": field[\"ind2\"],\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return [{\"leader\": record[\"leader\"][\"content\"], \"fields\": fields}]\n",
    "\n",
    "\n",
    "def get_url(identifiers, linktype):\n",
    "    \"\"\"\n",
    "    Loop through the identifiers to find the requested type of url.\n",
    "    \"\"\"\n",
    "    for identifier in identifiers:\n",
    "        if identifier[\"linktype\"] == linktype:\n",
    "            url = identifier[\"value\"]\n",
    "            return url\n",
    "\n",
    "\n",
    "def save_as_csv(list_dir, data, data_type):\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"pages\"] = df[\"pages\"].astype(\"Int64\")\n",
    "    df.to_csv(Path(list_dir, \"_data\", f\"{list_id}-{data_type}.csv\"), index=False)\n",
    "\n",
    "\n",
    "def get_list(list_id):\n",
    "    \"\"\"\n",
    "    Get a List record from the API.\n",
    "    \"\"\"\n",
    "    list_url = f\"https://api.trove.nla.gov.au/v3/list/{list_id}?encoding=json&reclevel=full&include=listItems\"\n",
    "    response = s.get(list_url, headers={\"X-API-KEY\": API_KEY})\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_article(id):\n",
    "    \"\"\"\n",
    "    Get a newspaper article record from the API\n",
    "    \"\"\"\n",
    "    article_api_url = f\"https://api.trove.nla.gov.au/v3/newspaper/{id}/?encoding=json&reclevel=full&include=tags\"\n",
    "    response = s.get(article_api_url, headers={\"X-API-KEY\": API_KEY})\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_work(id):\n",
    "    \"\"\"\n",
    "    Get a work record from the API.\n",
    "    \"\"\"\n",
    "    article_api_url = f\"https://api.trove.nla.gov.au/v3/work/{id}/?encoding=json&reclevel=full&include=workVersions,tags,links\"\n",
    "    response = s.get(article_api_url, headers={\"X-API-KEY\": API_KEY})\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def make_dirs(list_id):\n",
    "    \"\"\"\n",
    "    Create directories to store the outputs.\n",
    "    \"\"\"\n",
    "    list_dir = Path(\"cb-exhibitions\", list_id)\n",
    "    list_dir.mkdir(parents=True, exist_ok=True)\n",
    "    Path(list_dir, \"objects\").mkdir(exist_ok=True)\n",
    "    # Path(list_dir, \"temp\").mkdir(exist_ok=True)\n",
    "    Path(list_dir, \"_data\").mkdir(exist_ok=True)\n",
    "    return list_dir\n",
    "\n",
    "\n",
    "def get_all_tags(work):\n",
    "    tags = work.get(\"tag\", [])\n",
    "    for version in work[\"version\"]:\n",
    "        for record in version[\"record\"]:\n",
    "            for tag in record.get(\"tag\", []):\n",
    "                tags.append(tag[\"value\"])\n",
    "    return tags\n",
    "\n",
    "\n",
    "def get_subjects(work):\n",
    "    subjects = []\n",
    "    if \"subject\" in work:\n",
    "        subjects = work.get(\"subject\", [])\n",
    "    else:\n",
    "        subjects = []\n",
    "    subjects += get_all_tags(work)\n",
    "    return subjects\n",
    "\n",
    "\n",
    "def get_work_page_id(url):\n",
    "    nla_id = re.search(r\"https?://nla.gov.au/(nla.obj-\\d+)\", url).group(1)\n",
    "    metadata = get_metadata(url)\n",
    "    if metadata[\"pid\"] != nla_id:\n",
    "        for article in metadata.get(\"children\", {}).get(\"article\", []):\n",
    "            if article[\"pid\"] == nla_id:\n",
    "                page_ids = [p[\"page\"] for p in article.get(\"existson\", [])]\n",
    "                return page_ids\n",
    "    return [nla_id]\n",
    "\n",
    "\n",
    "def get_work_image_urls(record):\n",
    "    fulltext_url = get_url(record.get(\"identifier\", \"\"), \"fulltext\")\n",
    "    if fulltext_url and \"nla.obj\" in fulltext_url:\n",
    "        page_ids = get_work_page_id(fulltext_url)\n",
    "        image_urls = [f\"https://nla.gov.au/{p}/image\" for p in page_ids]\n",
    "    elif image_url := get_url(record.get(\"identifier\", \"\"), \"viewcopy\"):\n",
    "        image_urls = [image_url]\n",
    "    elif image_url := get_url(record.get(\"identifier\", \"\"), \"thumbnail\"):\n",
    "        image_urls = [image_url]\n",
    "    else:\n",
    "        image_urls = []\n",
    "    return image_urls\n",
    "\n",
    "\n",
    "def save_work_images(list_dir, record, max_size=1200):\n",
    "    filenames = []\n",
    "    image_urls = get_work_image_urls(record)\n",
    "    for i, image_url in enumerate(image_urls):\n",
    "        filename = Path(list_dir, \"objects\", f\"work-{record.get('id', '')}-{i}.jpg\")\n",
    "        filenames.append(filename)\n",
    "        if not filename.exists():\n",
    "            response = s.get(image_url)\n",
    "            if response.status_code == 200:\n",
    "                img = Image.open(BytesIO(response.content))\n",
    "                if max_size:\n",
    "                    img = contain(\n",
    "                        img, (max_size, max_size), method=Image.Resampling.LANCZOS\n",
    "                    )\n",
    "                img.save(filename, \"JPEG\")\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def get_article_tags(record):\n",
    "    subjects = []\n",
    "    article = get_article(record[\"id\"])\n",
    "    for tag in article.get(\"tag\", []):\n",
    "        subjects.append(tag[\"value\"])\n",
    "    return subjects\n",
    "\n",
    "\n",
    "def get_value(record, field, keys=[\"value\"]):\n",
    "    \"\"\"\n",
    "    Get the values of a field.\n",
    "    Some fields are lists of dicts, if so use the `key` to get the value.\n",
    "    \"\"\"\n",
    "    value = record.get(field, [])\n",
    "    if value and isinstance(value[0], dict):\n",
    "        for key in keys:\n",
    "            try:\n",
    "                return [re.sub(r\"\\s+\", \" \", v[key]) for v in value]\n",
    "            except KeyError:\n",
    "                pass\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def flatten_values(record, field, key=\"type\"):\n",
    "    \"\"\"\n",
    "    If a field has a value and type, return the values as strings with this format: 'type: value'\n",
    "    \"\"\"\n",
    "    flattened = []\n",
    "    values = record.get(field, [])\n",
    "    for value in values:\n",
    "        if key in value:\n",
    "            flattened.append(f\"{value[key]}: {value['value']}\")\n",
    "        else:\n",
    "            flattened.append(value[\"value\"])\n",
    "    return flattened\n",
    "\n",
    "\n",
    "def get_locations(work):\n",
    "    \"\"\"\n",
    "    Get locations from the spatial field.\n",
    "    If they are LoC GeographicAreas then get the place labels from mappings.\n",
    "    \"\"\"\n",
    "    locations = []\n",
    "    for location in work.get(\"spatial\", []):\n",
    "        if location.get(\"scheme\") == \"http://id.loc.gov/vocabulary/geographicAreas\":\n",
    "            locations.append(GEO_AREAS[location[\"value\"].strip(\"-\")][\"place\"])\n",
    "        else:\n",
    "            locations.append(location[\"value\"])\n",
    "    return locations\n",
    "\n",
    "\n",
    "def has_type(work, format_type):\n",
    "    \"\"\"\n",
    "    Check the metadata for a specific format value.\n",
    "    \"\"\"\n",
    "    for ft in work.get(\"type\", []):\n",
    "        if format_type in ft:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_coord(value, lat_lon):\n",
    "    \"\"\"\n",
    "    Make sure that lat/longs are within expected range.\n",
    "    Drop values if outside range.\n",
    "    \"\"\"\n",
    "    if lat_lon == \"lat\" and abs(value) <= 90:\n",
    "        return value\n",
    "    elif lat_lon == \"lon\" and abs(value) <= 180:\n",
    "        return value\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_center(parsed):\n",
    "    \"\"\"\n",
    "    Get the centre of a bounding box.\n",
    "    Returns point coords.\n",
    "\n",
    "    See: https://gis.stackexchange.com/a/394860\n",
    "    \"\"\"\n",
    "    e, w, n, s = itemgetter(\"east\", \"west\", \"north\", \"south\")(parsed)\n",
    "    width = max(w, e) - min(w, e)\n",
    "    # get the box height\n",
    "    height = max(s, n) - min(s, n)\n",
    "    # compute the center\n",
    "    center = check_coord(round(min(s, n) + height / 2, 4), \"lat\"), check_coord(\n",
    "        round(min(w, e) + width / 2, 4), \"lon\"\n",
    "    )\n",
    "    return center\n",
    "\n",
    "\n",
    "def parse_value(value):\n",
    "    \"\"\"\n",
    "    Parse latitude or longitude values.\n",
    "    \"\"\"\n",
    "    values = value.split(\"--\")\n",
    "    # Sometimes single hyphens are used\n",
    "    if len(values) == 1:\n",
    "        values = value.split(\"-\")\n",
    "    coords = [parse(v) for v in values]\n",
    "    return sorted(coords)\n",
    "\n",
    "\n",
    "def parse_coords(coords):\n",
    "    \"\"\"\n",
    "    Parses a coordinate string, converting values to decimal.\n",
    "\n",
    "    For points -- returns latitude and longitude.\n",
    "    For boxes -- returns centre of box as latitude, longitude, and bounds as east, west, north, and south.\n",
    "    \"\"\"\n",
    "    parsed = {}\n",
    "    # Default values\n",
    "    for c in [\"east\", \"west\", \"north\", \"south\", \"latitude\", \"longitude\"]:\n",
    "        parsed[c] = None\n",
    "    try:\n",
    "        # Split string into lat and long using /\n",
    "        long, lat = coords.split(\"/\")\n",
    "        if long.startswith(\"N\"):\n",
    "            long, lat = lat, long\n",
    "        longs = parse_value(long)\n",
    "        lats = parse_value(lat)\n",
    "    except (ValueError, TypeError):\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            # Bounding box\n",
    "            if len(longs) == 2 and len(lats) == 2:\n",
    "                parsed[\"east\"] = check_coord(longs[-1], \"lon\")\n",
    "                parsed[\"west\"] = check_coord(longs[0], \"lon\")\n",
    "                parsed[\"north\"] = check_coord(lats[-1], \"lat\")\n",
    "                parsed[\"south\"] = check_coord(lats[0], \"lat\")\n",
    "                # Get centre of bounding box\n",
    "                latitude, longitude = get_center(parsed)\n",
    "                parsed[\"latitude\"] = latitude\n",
    "                parsed[\"longitude\"] = longitude\n",
    "            # Point\n",
    "            elif len(longs) == 1 and len(lats) == 1:\n",
    "                parsed[\"latitude\"] = check_coord(lats[0], \"lat\")\n",
    "                parsed[\"longitude\"] = check_coord(longs[0], \"lon\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def get_coords(work):\n",
    "    fulltext_url = get_url(work.get(\"identifier\", []), \"fulltext\")\n",
    "    if fulltext_url and \"nla.obj\" in fulltext_url and has_type(work, \"Map\"):\n",
    "        metadata = get_metadata(fulltext_url)\n",
    "        marc_json = parse_marc(metadata)\n",
    "        # PyMARC expects a JSON string so we dump it to a string first\n",
    "        reader = JSONReader(json.dumps(marc_json))\n",
    "        for record in reader:\n",
    "            if coord_string := record[\"255\"][\"c\"]:\n",
    "                if coords := parse_coords(coord_string):\n",
    "                    return coords\n",
    "    for location in work.get(\"spatial\", []):\n",
    "        if location.get(\"scheme\") == \"http://id.loc.gov/vocabulary/geographicAreas\":\n",
    "            place = GEO_AREAS[location[\"value\"].strip(\"-\")]\n",
    "            coords = place.get(\"coordinates\", [])\n",
    "            for coord in coords:\n",
    "                lat, lon = coord.split(\",\")\n",
    "                return {\"latitude\": float(lat), \"longitude\": float(lon)}\n",
    "    return {}\n",
    "\n",
    "\n",
    "def update_config(list_data, list_dir):\n",
    "    with Path(\"cb-config\", \"_config.yml\").open(\"r\") as config_in:\n",
    "        config = yaml.safe_load(config_in)\n",
    "    config[\"title\"] = list_data[\"title\"]\n",
    "    config[\"author\"] = list_data[\"creator\"].replace(\"public:\", \"\")\n",
    "    config[\"metadata\"] = f'{list_data[\"id\"]}-items'\n",
    "    with Path(list_dir, \"_config.yml\").open(\"w\") as config_out:\n",
    "        config_out.write(yaml.dump(config))\n",
    "\n",
    "\n",
    "def harvest_list(list_id, max_size=1200):\n",
    "    list_dir = make_dirs(list_id)\n",
    "    data = get_list(list_id)\n",
    "    update_config(data, list_dir)\n",
    "    items = []\n",
    "    for item in tqdm(data[\"listItem\"]):\n",
    "        for zone, record in item.items():\n",
    "            if zone == \"work\":\n",
    "                # Some fields aren't included in the list data, so get the full work record\n",
    "                work_data = get_work(record[\"id\"])\n",
    "                coords = get_coords(work_data)\n",
    "                work = {\n",
    "                    \"objectid\": f\"work-{record.get('id', '')}\",\n",
    "                    \"parentid\": \"\",\n",
    "                    \"title\": record.get(\"title\", \"\"),\n",
    "                    \"type\": \";\".join(get_value(work_data, \"type\")),\n",
    "                    \"date\": record.get(\"issued\", \"\"),\n",
    "                    \"creator\": \"; \".join(get_value(work_data, \"contributor\")),\n",
    "                    \"is_part_of\": \"; \".join(flatten_values(work_data, \"isPartOf\")),\n",
    "                    \"publication_place\": \"; \".join(\n",
    "                        get_value(work_data, \"placeOfPublication\")\n",
    "                    ),\n",
    "                    \"trove_url\": record.get(\"troveUrl\", \"\"),\n",
    "                    \"source_url\": get_url(record.get(\"identifier\", \"\"), \"fulltext\"),\n",
    "                    \"abstract\": record.get(\"abstract\", \"\"),\n",
    "                    \"description\": item.get(\"note\", \"\"),\n",
    "                    \"subject\": \"; \".join(get_subjects(work_data)),\n",
    "                    \"extent\": work_data.get(\"extent\", \"\"),\n",
    "                    \"format\": \"; \".join(get_value(work_data, \"format\")),\n",
    "                    \"language\": \"; \".join(get_value(work_data, \"language\")),\n",
    "                    \"rights\": \"; \".join(get_value(work_data, \"rights\")),\n",
    "                    # coordinates for maps?\n",
    "                    \"location\": \"; \".join(get_locations(work_data)),\n",
    "                    \"latitude\": coords.get(\"latitude\", \"\"),\n",
    "                    \"longitude\": coords.get(\"longitude\", \"\"),\n",
    "                }\n",
    "                image_filenames = save_work_images(list_dir, work_data, max_size)\n",
    "                if len(image_filenames) > 1:\n",
    "                    work[\"format\"] = \"compound_object\"\n",
    "                    items.append(work)\n",
    "                    for i, image_file in enumerate(image_filenames):\n",
    "                        child_work = work.copy()\n",
    "                        child_work[\"parentid\"] = f\"work-{record.get('id', '')}\"\n",
    "                        child_work[\"objectid\"] = f\"work-{record.get('id', '')}-{i}\"\n",
    "                        child_work[\"filename\"] = image_file.name\n",
    "                        child_work[\"format\"] = \"image/jpeg\"\n",
    "                        items.append(child_work)\n",
    "                elif len(image_filenames) == 1:\n",
    "                    work[\"filename\"] = image_filenames[0].name\n",
    "                    work[\"format\"] = \"image/jpeg\"\n",
    "                    items.append(work)\n",
    "                else:\n",
    "                    work[\"format\"] = \"record\"\n",
    "                    items.append(work)\n",
    "            elif zone == \"article\":\n",
    "                newspaper_id = record.get(\"title\", {}).get(\"id\")\n",
    "                newspaper_title = record.get(\"title\", {}).get(\"title\")\n",
    "                newspaper_link = f'<a href=\"http://nla.gov.au/nla.news-title{newspaper_id}\">{newspaper_title}</a>'\n",
    "                # citation =\n",
    "                article = {\n",
    "                    \"objectid\": f\"article-{record.get('id', '')}\",\n",
    "                    \"parentid\": \"\",\n",
    "                    \"title\": record.get(\"heading\", \"\"),\n",
    "                    \"date\": record.get(\"date\", \"\"),\n",
    "                    \"is_part_of\": newspaper_link,\n",
    "                    \"pages\": record.get(\"pageSequence\", \"\"),\n",
    "                    \"trove_url\": f'http://nla.gov.au/nla.news-article{record.get(\"id\")}',\n",
    "                    \"type\": \"Newspaper article\",\n",
    "                    \"description\": item.get(\"note\", \"\"),\n",
    "                    \"subject\": \"; \".join(get_article_tags(record)),\n",
    "                    \"location\": \"\",\n",
    "                    \"latitude\": \"\",\n",
    "                    \"longitude\": \"\",\n",
    "                }\n",
    "                with tempfile.TemporaryDirectory() as dirpath:\n",
    "                    images = []\n",
    "                    tries = 0\n",
    "                    # Trove has had some issues loading newspaper images lately\n",
    "                    # This is an attempted workaround\n",
    "                    while not images and tries < 2:\n",
    "                        try:\n",
    "                            images = download_images(record[\"id\"], dirpath, masked=True)\n",
    "                        except UnidentifiedImageError:\n",
    "                            time.sleep(5)\n",
    "                            tries += 1\n",
    "                    # Use a page image if it can't get an article?\n",
    "                    if len(images) > 1:\n",
    "                        article[\"format\"] = \"compound_object\"\n",
    "                        items.append(article)\n",
    "                        for i, image in enumerate(images):\n",
    "                            if max_size:\n",
    "                                img = Image.open(Path(dirpath, image))\n",
    "                                img = contain(\n",
    "                                    img,\n",
    "                                    (max_size, max_size),\n",
    "                                    method=Image.Resampling.LANCZOS,\n",
    "                                )\n",
    "                                img.save(Path(list_dir, \"objects\", image), \"JPEG\")\n",
    "                            else:\n",
    "                                shutil.copy(\n",
    "                                    Path(dirpath, image),\n",
    "                                    Path(list_dir, \"objects\", image),\n",
    "                                )\n",
    "                            child_article = article.copy()\n",
    "                            child_article[\"format\"] = \"image/jpeg\"\n",
    "                            child_article[\"parentid\"] = (\n",
    "                                f\"article-{record.get('id', '')}\"\n",
    "                            )\n",
    "                            child_article[\"objectid\"] = (\n",
    "                                f\"article-{record.get('id', '')}-{i}\"\n",
    "                            )\n",
    "                            child_article[\"filename\"] = image\n",
    "                            items.append(child_article)\n",
    "                    elif len(images) == 1:\n",
    "                        article[\"format\"] = \"image/jpeg\"\n",
    "                        article[\"filename\"] = images[0]\n",
    "                        items.append(article)\n",
    "                    else:\n",
    "                        article[\"format\"] = \"record\"\n",
    "                        items.append(article)\n",
    "    if items:\n",
    "        save_as_csv(list_dir, items, \"items\")\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do it!\n",
    "\n",
    "Run the cell below to start the exhibition building process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297a5bcbad654658a3d64e43a71afe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "items = harvest_list(list_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the results\n",
    "\n",
    "Run the cell below to zip up all the harvested files and create a download link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a download=\"83777.zip\" href=\"cb-exhibitions/83777.zip\">Download your files</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_dir = Path(\"cb-exhibitions\", list_id)\n",
    "shutil.make_archive(list_dir, \"zip\", list_dir)\n",
    "HTML(f'<a download=\"{list_id}.zip\" href=\"{list_dir}.zip\">Download your files</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Created by [Tim Sherratt](https://timsherratt.org/) for the [GLAM Workbench](https://glam-workbench.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rocrate": {
   "author": [
    {
     "mainEntityOfPage": "https://timsherratt.au",
     "name": "Sherratt, Tim",
     "orcid": "https://orcid.org/0000-0001-7956-4498"
    }
   ],
   "category": "Lists",
   "description": "This notebook converts [Trove lists](https://trove.nla.gov.au/help/become-voluntrove/lists) into a series of files that can be uploaded to a [CollectionBuilder-GH](https://github.com/CollectionBuilder/collectionbuilder-gh) repository to create an instant exhibition. See the [CollectionBuilder site](https://collectionbuilder.github.io/) for more information on how CollectionBuilder works and what it can do.",
   "mainEntityOfPage": "https://glam-workbench.net/trove-lists/convert-list-to-cb-exhibition/",
   "name": "Convert a Trove list into a CollectionBuilder exhibition",
   "position": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
